{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2086135",
   "metadata": {},
   "source": [
    "# PROJECT: Wrangle and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "2ff2331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import requests\n",
    "import tweepy as tw\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "5a9aa48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "299629e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676ad2e",
   "metadata": {},
   "source": [
    "# Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "869fdf83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  "
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the tweet archive tweet obtained as a handheld file\n",
    "\n",
    "archive = pd.read_csv(\"twitter-archive-enhanced.csv\")\n",
    "archive.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "f0761379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of twitter ids present in archive table\n",
    "id_list = list(archive.tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefdbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9904a40",
   "metadata": {},
   "source": [
    "## Programmatically downloading image prediction file from url link \n",
    "#-- https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "18239230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make directory --image predictions\n",
    "\n",
    "folder = \"image_prediction\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "#Obtain response from url using the request library\n",
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "#load the dcontent of the data into a file in the created folder\n",
    "\n",
    "with open(os.path.join(folder, url.split(\"/\")[-1]), \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25dcfc",
   "metadata": {},
   "source": [
    "## Accessing additional twitter information from twitter's API using tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "3513d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing twitter developer keys\n",
    "\n",
    "with open(\"twitter_keys.txt\", \"r\") as file:\n",
    "    keys = file.readlines()\n",
    "\n",
    "API_key = keys[0].strip(\"\\n\")\n",
    "API_key_secret = keys[1].strip(\"\\n\")\n",
    "Bearer_token = keys[2].strip(\"\\n\")\n",
    "Access_token = keys[3].strip(\"\\n\")\n",
    "Access_secret = keys[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "1182a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the api class using the obtained the deveolper keys\n",
    "\n",
    "#Authentication\n",
    "auth = tw.OAuthHandler(API_key, API_key_secret)\n",
    "auth.set_access_token(Access_token, Access_secret)\n",
    "\n",
    "api = tw.API(auth, wait_on_rate_limit = True)  #Initializing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "243d09f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-626-35eb202ebdd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#using api class to access tweet via the tweet id obtained in the first table --archive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlen_id_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0merror_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'time'"
     ]
    }
   ],
   "source": [
    "#using api class to access tweet via the tweet id obtained in the first table --archive\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "len_id_list = len(id_list)\n",
    "error_dict = {}\n",
    "with open(\"json-text.txt\", \"w\") as file:\n",
    "    for tweet_id in id_list:\n",
    "        count+=1\n",
    "        print(count, f\"out of {len_id_list}\")\n",
    "        try:\n",
    "            response = api.get_status(tweet_id, tweet_mode = \"extended\")\n",
    "            json.dump(response._json, file)\n",
    "            file.write(\"\\n\")\n",
    "            print(\"success\")\n",
    "            #continue\n",
    "        except tw.TweepyException as e:\n",
    "                print(\"Failed\")\n",
    "                error_dict[tweet_id] = e\n",
    "        pass\n",
    "        pass\n",
    "    pass\n",
    "time_taken = time.time() - start_time\n",
    "print(time_taken)\n",
    "print(error_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "ed139bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654165844.0826602"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c082af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load each line of the txt json-text.txt file just created and append it\n",
    "#to empty list json_list\n",
    "json_list = []\n",
    "with open(\"json-text.txt\", \"r\") as file:\n",
    "    for x in id_list:\n",
    "        json_list.append(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_list = []\n",
    "len_ = len(json_list)  #obatain length of list to iterate over\n",
    "for i in len_:\n",
    "    if not json_list[i]:   #This condition tests if the json_string is empty\n",
    "        continue\n",
    "    else:\n",
    "        json_load = json.loads(json_list[i])\n",
    "        tweet_id = json_load[\"id_str\"]\n",
    "        time = json_load[\"created_at\"]\n",
    "        likes = json_load[\"favorite_count\"]\n",
    "        retweet_counts = json_load[\"retweet_count\"]\n",
    "        json_dict = {\"tweet_id\": tweet_id,\n",
    "                    \"timestamp\": time,\n",
    "                    \"likes\": likes,\n",
    "                    \"retweet_count\": retweet_counts}\n",
    "    pd_list.append(json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info = pd.DataFrame(pd_list)  #use pd.DataFrame for make dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66623d3",
   "metadata": {},
   "source": [
    "#### Load and print all three tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e21199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First table, archives of tweet handed over\n",
    "archive.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2481be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second tabele stored in image prediction folder\n",
    "\n",
    "img_prediction = pd.read_csv(\"./image_prediction/image-predictions.tsv\", sep = \"\\t\")\n",
    "img_prediction.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d583b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6922d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fae7197",
   "metadata": {},
   "source": [
    "# Asessing the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb154a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive.to_csv(\"archive.csv\", index = False)\n",
    "img_prediction.to_csv(\"img_prediction.csv\", index = False)\n",
    "additional_info.to_csv(\"add_info.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0b04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archive.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60f71d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674926a",
   "metadata": {},
   "source": [
    "From the above we can spot incomplete columns and invalid datatypes as detailedly refreenced below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b2325",
   "metadata": {},
   "source": [
    "In order to have a visual view and asssessment of the non null values of the retweet_id columns, we will run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050626f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archive[archive.in_reply_to_status_id.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431444de",
   "metadata": {},
   "source": [
    "Let us further investigate the unique properties of the dog stages columns and have a clearer of perspective of what data we are dealing with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77189758",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(archive.pupper.nunique())\n",
    "print(archive.pupper.unique())\n",
    "\n",
    "print(archive.puppo.nunique())\n",
    "print(archive.puppo.unique())\n",
    "\n",
    "print(archive.doggo.nunique())\n",
    "print(archive.doggo.unique())\n",
    "\n",
    "print(archive.floofer.nunique())\n",
    "print(archive.floofer.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa67e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(archive.puppo.isnull()) #This examine to see if empty values are accurately represented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508b018",
   "metadata": {},
   "source": [
    "Investigate the source column programmatically to see the column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4a758",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "archive.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(archive.tweet_id.duplicated()) #Check for duplicates -- found none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e035904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(archive.rating_numerator.nunique())\n",
    "print(archive.rating_numerator.unique())\n",
    "\n",
    "print(archive.rating_denominator.nunique())\n",
    "print(archive.rating_denominator.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive[archive.name == \"None\"]  #An iterating step brought me back to exmine and check for names recorded as None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9a2df",
   "metadata": {},
   "source": [
    "**Check for img_prediction table next**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f334eb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64664052",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prediction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prediction.img_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(img_prediction.jpg_url.duplicated()) #Check for same image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb82cc0",
   "metadata": {},
   "source": [
    "**Check for additional_info table next**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa6bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "additional_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b472b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53872f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "additional_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9eed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(additional_info.tweet_id.duplicated()) #Check for duplicate tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab426d6",
   "metadata": {},
   "source": [
    "### Documenting Assessments from Archive table\n",
    "##### Quality Issues\n",
    "- Highly missing values in columns (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp and expanded_urls(few missing values for expanded urls))\n",
    "- timestamp column contains extra +0000 character at the end and also time values which might not be necessary for analysis\n",
    "- Wrong datatype\n",
    "    - tweet_id, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id(string is appropriate)\n",
    "    - timestamp, retweeted_status_timestamp are not datetime datatype\n",
    "- doggo, floofer, pupper and puppo columns use None instead of NaN\n",
    "- Source column contains the soure of each tweet and datatype should be category.\n",
    "- Some tweets are retweets. Tweets that have non-null retweet_id. They are not regarded as original tweets.\n",
    "- The rating_numerator and rating_numerator can be combined as one observatory value as rating.\n",
    "- Recorded name as None\n",
    "\n",
    "##### Tidyness Issues\n",
    "- Values as columns in doggo, floofer, pupper and puppo columns\n",
    "\n",
    "\n",
    "### Documenting Assessments from img_prediction table\n",
    "##### Quality Issues\n",
    "- tweet_id should be string\n",
    "- The first 3 columns seem to be the only relevant for the analysis we want to perform.\n",
    "- Duplicate image urls\n",
    "- descriptive column name (img_num)\n",
    "\n",
    "### Documenting Assessments from additional_info table\n",
    "##### Quality Issues\n",
    "- timestamp has extra +0000 characters and should be datetime object\n",
    "\n",
    "##### Tidyness Issues\n",
    "- Merge all three tables as tweet-master-archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a98b913",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c739477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies of each dataframe\n",
    "\n",
    "archive_clean = archive.copy()\n",
    "img_prediction_clean = img_prediction.copy()\n",
    "additional_info_clean = additional_info.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921736a",
   "metadata": {},
   "source": [
    "### Issue #1: \n",
    "Archive table - Highly missing values in columns (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp and expanded_urls(few missing values for expanded urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f7fb2",
   "metadata": {},
   "source": [
    "The reason for this highly missing values in the column is because of nature of tweet. For example, only tweets that are retweet have retweet_id e.t.c.\n",
    "    \n",
    "We are however dealing with original tweets and not retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae068fde",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "- Slice table for where retweet_id is null and drop all retweet related columns\n",
    "- Drop the in_reply columns and expanded urls (they contribute little or nothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ac093",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive_clean[archive_clean.retweeted_status_id.isnull()] #slicing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.drop([\"retweeted_status_id\", \n",
    "                    \"retweeted_status_user_id\", \"retweeted_status_timestamp\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.drop([\"in_reply_to_status_id\", \n",
    "                    \"in_reply_to_user_id\", \n",
    "                    \"expanded_urls\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958d344",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "Note: The number of non null retweet columns was 181 from a dataframe of originally 2356 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6debdf8f",
   "metadata": {},
   "source": [
    "### Issue #2: \n",
    "- Values as columns in doggo, floofer, pupper and puppo columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d428d4",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "- Melt the dataframe to have one column as dog_stage and value that shows the actual dog_stage.\n",
    "- Drop the var_name column\n",
    "- Sort dataframe by tweet_id, and value_name, then drop dupliactes exploiting the structure of the rearranged df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3141cf",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_cols = set(archive_clean.columns)\n",
    "stage_cols = {\"doggo\", \"floofer\", \"pupper\", \"puppo\"}\n",
    "id_vars = list(arch_cols - stage_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53646973",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = pd.melt(archive_clean, id_vars = id_vars, \n",
    "        var_name = \"dog_stage_class\", \n",
    "        value_name=\"dog_stage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08998a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the var_name\n",
    "archive_clean.drop(\"dog_stage_class\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222721a",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775eb734",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.dog_stage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(archive_clean.dog_stage!=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2b402",
   "metadata": {},
   "source": [
    "### Issue #3: \n",
    "- doggo, floofer, pupper and puppo columns use None instead of NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44230aae",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "- Replace \"None\" with np.nan\n",
    "- Exploit the nature of nan to sort the dataframe by tweet_id and dog_stage, then use this structure to obtain unique tweet ids while retaining values where a particular tweet has a value apart from none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5002c1",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.dog_stage = archive_clean.dog_stage.replace(\"None\", np.nan) #replace with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive_clean.sort_values([\"tweet_id\", \"dog_stage\"], na_position = \"last\")\n",
    "archive_clean = archive_clean.drop_duplicates(subset =\"tweet_id\", keep = \"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf630bf",
   "metadata": {},
   "source": [
    "#### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913adb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.shape  #we are expecting just the shape of the dataset to remain uncanged i.e. 2175 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.dog_stage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(archive_clean.dog_stage.notnull())  \n",
    "#The value (344 as opposed to 356) here show that there are some rows which posibbly have two different dog stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6415b",
   "metadata": {},
   "source": [
    "### Issue #4: \n",
    "- timestamp column contains extra +0000 character at the end and also time values which might not be necessary for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eba7a2",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "- slice string to retain valuable characters\n",
    "- convert column to datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a929a59",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0298bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.timestamp = archive_clean.timestamp.apply(lambda x: x.split(\"+\")[0]) #string to extract strict date time values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ca651",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.timestamp = pd.to_datetime(archive_clean.timestamp)  #Conert to datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add815f",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.timestamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f689587",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.timestamp.dtype #Check for datatype of the column timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90835d8c",
   "metadata": {},
   "source": [
    "### Issue #5: \n",
    "- tweet_id column of archive table datatype to string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645bf01",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "- Convert column to string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98191c5",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.tweet_id = archive_clean.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4260f67",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.tweet_id.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e8779",
   "metadata": {},
   "source": [
    "### Issue #6: \n",
    "- Source column contains the soure of each tweet and datatype should be category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b594eb",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "- Split the column by delimeter \">\" and select nth index as appropriate.\n",
    "- Convert column to category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a694712d",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split column by delimeter \">\" and extract valid string\n",
    "\n",
    "archive_clean.source = archive_clean.source.apply(lambda x: x.split(\">\")[1][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to category\n",
    "\n",
    "archive_clean.source = archive_clean.source.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f69cf",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddab6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da18d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7342d228",
   "metadata": {},
   "source": [
    "### Issue #7: \n",
    "- The rating_numerator and rating_numerator can be combined as one observatory value as rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f80c663",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "\n",
    "- Divide the rating numerator by the denominator and record as rating\n",
    "- Drop rating_numerator and rating_denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a8431",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean[\"rating\"] = archive_clean.rating_numerator/archive_clean.rating_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.drop([\"rating_numerator\", \"rating_denominator\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca460c8b",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc953a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf69b1b",
   "metadata": {},
   "source": [
    "### Issue #8: \n",
    "\n",
    "- The None value of the name column can be left as None or renamed as unnamed or another variable but I would not really support using np.nan as a value, maybe not available because they are tweets that did not reference the name of the particular dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e2567",
   "metadata": {},
   "source": [
    "### Issue #9: \n",
    "\n",
    "- img_prediction table: The first 3 columns seem to be the only relevant for the analysis we want to perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812f72d",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4505565",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prediction_clean = img_prediction_clean[[\"tweet_id\", \"jpg_url\", \"img_num\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb906d5",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb500f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_prediction_clean.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5ae17",
   "metadata": {},
   "source": [
    "### Issue #10: \n",
    "\n",
    "- img_prediction: tweet_id should be string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de455970",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prediction_clean.tweet_id = img_prediction_clean.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320e727",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296ea1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_prediction_clean.tweet_id.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4e5d4",
   "metadata": {},
   "source": [
    "### Issue #11: \n",
    "\n",
    "- img_num: Rename img_num to img_classifiacation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08899975",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prediction_clean.rename(columns = {\"img_num\": \"img_class\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5baf57",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2601e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_prediction_clean.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc34830",
   "metadata": {},
   "source": [
    "### Issue #12: \n",
    "\n",
    "- jpg_url duplicate suggests that multiple tweets point to a particular img which is not an uncommon thing. so we will preserve this information and not delete the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1b4de",
   "metadata": {},
   "source": [
    "### Issue #13: \n",
    "\n",
    "- additional_info: timestamp has extra +0000 characters and should be datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db4363",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info_clean.timestamp = pd.to_datetime(additional_info_clean.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687aaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info_clean.timestamp = pd.to_datetime(additional_info_clean.timestamp.apply(lambda x: str(x).split(\"+\")[0]))\n",
    "#string to extract strict date time values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7379948a",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421ae82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "additional_info_clean.timestamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde33949",
   "metadata": {},
   "source": [
    "### Tidyness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069fcbb",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- Merge all three tables to be a master dataframe for classifying and rating dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f8ce3",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a04e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive = pd.merge(archive_clean, img_prediction_clean, how = \"inner\", on = \"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b39a09",
   "metadata": {},
   "source": [
    "In order to mege the twiiter master df to the additional information, we will need to drop the timestamp of the additional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info_clean.drop(\"timestamp\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8218f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with twitter master archive\n",
    "\n",
    "twitter_master_archive = pd.merge(twitter_master_archive, additional_info_clean, how = \"inner\", on = \"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4185fd",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446edb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83610493",
   "metadata": {},
   "source": [
    "Convert img_class to categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive.img_class = twitter_master_archive.img_class.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c311c8d",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449020a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save master dataframe\n",
    "\n",
    "twitter_master_archive.to_csv(\"twitter_archive_master.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08914667",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f9522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_master_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive.describe(include = \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f181ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a135b053",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1. The average rating for each dog is 1.17 approximately which is greater than 1. This tells us about how wedogrates do rate the dogs.\n",
    "\n",
    "2. The average number of likes/favourites and retweets that they receive per tweet is 7727 and 2250 respectively, while the maximum likes and retweets are 145159 and 70940 respectively\n",
    "\n",
    "3. We have up to 545 unnamed dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eccfdb",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_master_archive.source.value_counts(normalize = True).plot(kind = \"bar\")\n",
    "plt.title(\"Barplot comapring the count of \\ndifferent sources of tweet\", fontsize = 14)\n",
    "plt.ylabel(\"count\", fontsize = 12, weight = \"bold\")\n",
    "plt.xlabel(\"sources of tweet\", fontsize = 12, weight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841aa6e",
   "metadata": {},
   "source": [
    "Most of the tweets from wedogrates are made from iphone and a very inconsequential amount is made from Twitteer for Web Client, where all others can be overlooked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = twitter_master_archive, x = \"img_class\", y = \"rating\")\n",
    "plt.title(\"Barplot of image classification compared to the ratings received\")\n",
    "plt.ylabel(\"rating\", fontsize = 12, weight = \"bold\")\n",
    "plt.xlabel(\"image classification\", fontsize = 12, weight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe53cb9",
   "metadata": {},
   "source": [
    "- Image class 1 has the highest spread of rating from about 1.0 to 1.4 - This is represented in the wick above each bar in the barplot above.\n",
    "\n",
    "- The average ratings for each image classification are similar. The image classification 4 however stands to be the highest.\n",
    "\n",
    "- The average rating is represented by the heights of the bar (without the wicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51938c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data = twitter_master_archive, x = \"dog_stage\", y = \"rating\")\n",
    "plt.title(\"Barplot of dog stage compared to the ratings received\")\n",
    "plt.ylabel(\"rating\", fontsize = 12, weight = \"bold\")\n",
    "plt.xlabel(\"dog stage\", fontsize = 12, weight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc43720",
   "metadata": {},
   "source": [
    "- The rating pupper is the lowest among other form of dog stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150d88c",
   "metadata": {},
   "source": [
    "While rating and favourites count seem to be metrics for evaluating a dog, they both are metrics from different perspective. The likes being the metrics from public opinions (voting), while the rating came from enterprise metrics.\n",
    "\n",
    "First we want to see how much do ratings and likes count correlate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557ba1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scatter plot of likes and rating\n",
    "\n",
    "plt.scatter(twitter_master_archive.rating, twitter_master_archive.likes)\n",
    "plt.title(\"Scatter plot of rating against the likes\", fontsize = 14)\n",
    "plt.xlabel(\"likes count\", fontsize = 12, weight = \"bold\")\n",
    "plt.ylabel(\"ratings\", fontsize = 12, weight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6f46b",
   "metadata": {},
   "source": [
    "The scatterplot is not properly vizualized because of outliers in the likes count axis. (ratings > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical correlation between the metrics of interest\n",
    "twitter_master_archive.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e622fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop index of likes greater than 2\n",
    "row_to_drop = twitter_master_archive[twitter_master_archive.rating > 2]\n",
    "ind_to_drop = row_to_drop.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot scatterplot of adjusted table\n",
    "plt.scatter(twitter_master_archive.drop(index = ind_to_drop).rating, twitter_master_archive.drop(index = ind_to_drop).likes)\n",
    "plt.title(\"Scatter plot of rating against the likes\", fontsize = 14)\n",
    "plt.xlabel(\"likes count\", fontsize = 12, weight = \"bold\")\n",
    "plt.ylabel(\"ratings\", fontsize = 12, weight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fc1d3",
   "metadata": {},
   "source": [
    "There is very little correlation as already shown in the correlation table, however the relationship is a positive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc4e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcf48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
